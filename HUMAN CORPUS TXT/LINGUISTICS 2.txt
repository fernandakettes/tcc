TITLE: Assessing the Linguistic Productivity of Unsupervised Deep Neural Networks
AUTHOR: Lawrence Phillips, Nathan Hodas
YEAR: 2017

Computational modeling has long played a significant role within cognitive science, allowing researchers to explore the implications of cognitive theories and to discover what properties are necessary to account for particular phenomena (J. L. McClelland, 2009). Over time, a variety of modeling traditions have seen their usage rise and fall. While the 1980s saw the rise in popularity of connectionism (Thomas & McClelland, 2008), more recently symbolic Bayesian models have risen to prominence (Chater & Oaksford, 2008; Lee, 2011). While the goals of cognitive modelers have largely remained the same, increases in computational power and architectures have played a role in these shifts (J. L. McClelland, 2009). Following this pattern, recent advances in the area of deep learning (DL) have led to a rise in interest from the cognitive science community as demonstrated by a number of recent workshops dedicated to DL (Saxe, 2014; J. McClelland, Hansen, & Saxe, 2016; J. McClelland, Frank, & Mirman, 2016). As with any modeling technique, DL can be thought of as a tool which is best suited to answering particular types of questions. One such question is that of learnability, whether an output behavior could ever be learned from the types of input given to a learner. These types of questions play an integral role in the field of language acquisition where researchers have argued over whether particular aspects of language could ever be learned by a child without the use of innate, language-specific mechanisms (Smith, 1999; C. D. Yang, 2004; Chater & Christiansen, 2010; Pearl, 2014). The success of a domain general learner does not necessarily imply that human learners acquire the phenomenon in a similar fashion, but it does open the possibility that we need not posit innate, domain-specific knowledge. The crux of these learning problems typically lies in making a particular generalization which goes beyond the input data. One major type of generalization that DL models would need to capture is known as linguistic productivity. A grammatical rule is considered productive when it can be applied in novel situations. For example, as a speaker of English you may never have encountered the phrase a gavagai before, but you now knowthat gavagai must be a noun and can therefore combine with other determiners to produce a phrase such as the gavagai. Before DL might be applied to larger questions within language acquisition, the issue of productivity must f irst be addressed. If DL models are not capable of productivity, then they cannot possibly serve to model the cognitive process of language acquisition. On the other hand, if DL models demonstrate basic linguistic productivity, we must explore what aspects of the models allow for this productivity.

The Special Case of Determiners For decades, debate has raged regarding the status of productive rules among children acquiring their native language. On the one hand, some have argued that children seem hardwired to apply rules productively and demonstrate this in their earliest speech (Valian, Solt, & Stewart, 2009; C. Yang, 2011). On the other, researchers have argued that productivity appears to be learned, with children’s early speech either lacking productivity entirely or increasing with age (Pine & Martindale, 1996; Pine, Freudenthal, Krajewski, & Gobet, 2013; Meylan, Frank, Roy, & Levy, 2017). Of particular interest to this debate has been the special case of English determiners. In question is whether or not English-learning children have acquired the specific linguistic rule which allows them to create a noun phrase (NP) from a determiner (DET) and noun (N) or if they have simply memorized the combinations that they have previously encountered. This linguistic rule, NP DETN, is productive in two senses. First, it can be applied to novel nouns, e.g. a gavagai. Second, consider the determiners a and the. If a singular noun can combine with one of these determiners, it may also combine with the other, e.g. the wug. This type of rule seems to be acquired quite early in acquisition, making it appropriate to questions of early productivity, and provides an easy benchmark for a DL model. Yet answering such a simple question first requires addressinghow one might measure productivity. Most attempts to measure productivity have relied on what is known as an overlap score, intuitively what percentage of nouns occur with both a and the (C. Yang, 2011). This simple measure has been the source of some controversy. C. Yang (2011) argues that early attempts failed to take into account the way in which word frequencies affect the chance for a word to “overlap”. Because word frequency follows a Zipfian distribution, with a long tail of many infrequent words, many nouns are unlikely to ever appear with both determiners. He proposes a method to calculate an expected level of overlap which takes into account these facts. Alternatively, Meylan et al. (2017) propose a Bayesian measure of productivity which they claim takes into account the fact that certain nouns tend to prefer one determiner over another. For instance, while one is more likely to hear a bath than the phrase the bath, the opposite is true of the noun bathroom which shows a preference for the determiner the (Meylan et al., 2017). The literature is quite mixed regarding whether or not children show early productivity. Differences in pre-processing have lead researchers to draw opposite conclusions from similar data, making interpretation quite difficult (C. Yang, 2011; Pine et al., 2013). Indeed, most corpora involving individual children are small enough that Meylan et al. (2017) argue it is impossible to make a statistically significant claim as to child productivity. For analyzing whether or not text generated by a DL model is productive or not, we thankfully do not need to fully address the problem of inferring child productivity. Ideally, the model would demonstrate a similar level of overlap to the data it was exposed to. We make use of the overlap statistic from Yang because it is more easily comparable to other works and has been better studied than the more recent Bayesian metric of Meylan et al. (2017). Deep Learning for Language Acquisition Deep learning, or deep neural networks, are an extension of traditional artificial neural networks (ANN) used in connectionist architectures. A “shallow” ANN is one that posits a single hidden layer of neurons between the input and output layers. Deep networks incorporate multiple hidden layers allowing these networks in practice to learn more complex functions. The model parameters can be trained through the use of the backpropogation algorithm. The addition of multiple hidden layers opens up quite a number of possible architectures, not all of which are necessarily applicable to problems in cognitive science or language acquisition more specifically. While the most common neural networks are discriminative, i.e. categorizing data into specific classes, a variety of techniques have been proposed to allow for truly generative neural networks. These generative networks are able to take in input data and generate complex outputs such as images or text which makes them ideal for modeling human behavior. We focus on one generative architecture in particular known as a deep autoencoder (AE) (Hinton & Salakhutdinov, 2006). While AEshave been used for a variety of input data types, most prominently images, we describe their use here primarily for text. The first half, the encoder, takes in sentences and transforms them into a condensed representation. This condensed representation is small enough that the neural network cannot simply memorize each sentence and instead is forced to encode only the aspects of the sentence it believes to be most important. The second half, the decoder, learns to take this condensed representation and transform it back into the original sentence. Backpropogation is used to train model weights to reduce the loss between the original input and the reconstructed output. Although backpropagation is more typically applied to supervised learning problems, the process is in fact unsupervised because the model is only given input examples and is given no external feedback. AEs have been shown to successfully capture text representations in areas such as paragraph generation (Li, Luong, & Jurafsky, 2015), part-of-speech induction (Vishnubhotla, Fernandez, & Ramabhadran, 2010), bilingual word representations (Chandar et al., 2014), and sentiment analysis (Socher, Pennington, Huang, Ng, & Manning, 2011), but have not been applied to modeling language acquisition. While any number of DL architectures could be used to model language acquisition, the differences between ANNs and actual neurons in the brain make any algorithmic claims difficult. Instead, DL models might be used to address computational level questions, for instance regarding whether or not a piece of knowledge is learnable from the data encountered by children. Before this can be done, however, it remains to be seen whether DL models are even capable of creating productive representations. If they cannot, then they do not represent useful models of language acquisition. This work attempts to address this not by creating a model of how children acquire language, but by using methods from the psychological literature on productivity to assess the capability of DL to learn productive rules.
